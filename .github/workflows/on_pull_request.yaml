name: On pull request

on:
  pull_request:
    types: [ opened, reopened, synchronize ]

jobs:
  web_test:
    runs-on: ubuntu-latest
    env:
      # ---------- ENDPOINT
      BASE_API_URL: ${{ vars.BASE_API_URL }}
      BASE_URL: ${{ vars.BASE_URL }}
      GH_API_URL: ${{ github.api_url }}
      # ---------- COMMON
      API_LOG_LVL: ${{ vars.API_LOG_LVL }}
      ENV: ci
      LOG_LVL: ${{ vars.LOG_LVL }}
      PYTEST_ARGS: ${{ vars.PYTEST_ARGS_API }}
      PYTEST_MARK_EXPR: ${{ vars.PYTEST_MARK_EXPR_API }}
      # ---------- API
      DEFAULT_USER_AGENT: ${{ vars.DEFAULT_USER_AGENT }}
      HTTP_TIMEOUT: ${{ vars.HTTP_TIMEOUT }}
      # ---------- UI
      ALLURE_ATTACH_TEST_ARTIFACTS: ${{ vars.ALLURE_ATTACH_TEST_ARTIFACTS }}
      ALLURE_ATTACH_TEST_VIDEO: ${{ vars.ALLURE_ATTACH_TEST_VIDEO }}
      BROWSER_NAME: ${{ vars.BROWSER_NAME }}
      BROWSER_VERSION: ${{ vars.BROWSER_VERSION }}
      BROWSER_SIZE: ${{ vars.BROWSER_SIZE }}
      BROWSER_HEADLESS: ${{ vars.BROWSER_HEADLESS }}
      BROWSER_TIMEOUT: ${{ vars.BROWSER_TIMEOUT }}
      BROWSER_SCRIPTS_TIMEOUT: ${{ vars.BROWSER_SCRIPTS_TIMEOUT }}
      BROWSER_PAGE_LOAD_STRATEGY: eager
      BROWSER_PAGE_LOAD_TIMEOUT: ${{ vars.BROWSER_PAGE_LOAD_TIMEOUT }}
      BROWSER_DOWNLOAD_DIR: ${{ vars.BROWSER_DOWNLOAD_DIR }}
      BROWSER_OVERRIDE_DOWNLOADED_FILE_DIR: ${{ vars.BROWSER_OVERRIDE_DOWNLOADED_FILE_DIR }}
      BROWSER_REMOTE_VNC: ${{ vars.BROWSER_REMOTE_VNC }}
      BROWSER_REMOTE_VIDEO: ${{ vars.BROWSER_REMOTE_VIDEO }}
      BROWSER_REMOTE_LOGS: ${{ vars.BROWSER_REMOTE_LOGS }}
      BROWSER_REMOTE_AUDIO: ${{ vars.BROWSER_REMOTE_AUDIO }}
      BROWSER_REMOTE_SESSION_TIMEOUT: ${{ vars.BROWSER_REMOTE_SESSION_TIMEOUT }}
      DEFAULT_PERCENT_OF_TOLERANCE: ${{ vars.DEFAULT_PERCENT_OF_TOLERANCE }}
      DEFAULT_SCREENSHOT_TIMEOUT: ${{ vars.DEFAULT_SCREENSHOT_TIMEOUT }}
      PATH_TO_FILES: ${{ vars.PATH_TO_FILES }}
      REMOTE_TYPE: ${{ vars.REMOTE_TYPE }}
      REMOTE_URL: ${{ vars.REMOTE_URL }}
      REWRITE_ALL_SCREENSHOTS: false
      # ---------- GITHUB
      GH_TOKEN: ${{ secrets.GH_TOKEN }}
      GH_TOKEN_NAME: ${{ vars.GH_TOKEN_NAME }}
      GH_ACCOUNT_NAME: ${{ github.repository_owner }}
      GH_REPO_NAME: ${{ vars.GH_REPO_NAME }}
      # ---------- EXPECTED DATA
      DEFAULT_EMAIL: ${{ secrets.DEFAULT_EMAIL }}
      DEFAULT_PASSWORD: ${{ secrets.DEFAULT_PASSWORD }}
      EMAIL_DOMAIN: ${{ secrets.EMAIL_DOMAIN }}
      EXPECTED_PRODUCT_ID: ${{ vars.EXPECTED_PRODUCT_ID }}
      EXPECTED_PRODUCT_IDS: ${{ vars.EXPECTED_PRODUCT_IDS }}
      EXPECTED_CREDIT_CARD: ${{ vars.EXPECTED_CREDIT_CARD }}
      RECOMMENDED_PRODUCT_IDS: ${{ vars.RECOMMENDED_PRODUCT_IDS }}
      # ---------- OTHER
      ARCH: ${{ vars.ARCH }}
      BUILD_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
      PREFIX: ${{ github.repository_owner }}
      PYTHON_VERSION: ${{ vars.PYTHON_VERSION }}
      SHOW_LOGS: ${{ vars.SHOW_TEST_CONTAINER_LOGS }}
      TESTS_PASS_RATE: ${{ vars.TESTS_PASS_RATE }}

    steps:

      - name: Get current date/time
        run: |
          echo "CURRENT_DATE_TIME=$(date '+%Y-%m-%d %H:%M:%S')" >> $GITHUB_ENV

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ env.GITHUB_SHA }}

      - name: Get the last commit message
        run: |
          echo "HEAD_COMMIT_MESSAGE=$(git show -s --format=%s)" >> $GITHUB_ENV

      - name: Setup Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: "${{ env.PYTHON_VERSION }}"

      - name: Pull Browser selenoid/vnc_${{ env.BROWSER_NAME }}:${{ env.BROWSER_VERSION }}
        run: |
          docker pull selenoid/vnc_${{ env.BROWSER_NAME }}:${{ env.BROWSER_VERSION }}
          docker pull selenoid/video-recorder:latest-release

      - name: Checkout workflow-resources branch
        uses: actions/checkout@v4
        with:
          ref: workflow-resources
          path: workflow-resources

      - name: Prepare workflow-resources directory
        run: |
          set -e
          mkdir -p workflow-resources/screenshot

      - name: Run API tests
        id: api_test_run
        if: always()
        run: |
          set -euo pipefail

          docker compose -f docker-compose.ci.yaml up -d
          docker ps -a
          docker wait automation-exercise-tests

          if [ "${{ env.SHOW_LOGS }}" = "true" ]; then
            echo "### Test logs ###"
            docker logs automation-exercise-tests
          fi

        continue-on-error: true

      - name: Clear compose data
        if: always()
        run: |
          docker compose rm -sf
          docker rmi ${{ env.PREFIX }}/automation-exercise-tests:latest

      - name: Update env variables for UI test run
        if: always()
        run: |
          echo "PYTEST_MARK_EXPR=${{ vars.PYTEST_MARK_EXPR_WEB }}" >> $GITHUB_ENV
          echo "PYTEST_ARGS=${{ vars.PYTEST_MARK_EXPR_WEB }}" >> $GITHUB_ENV
          echo "PAGE_LOAD_STRATEGY=eager" >> $GITHUB_ENV

      - name: Run UI tests
        id: web_test_run
        if: always()
        run: |
          set -euo pipefail

          docker compose -f docker-compose.ci.yaml up -d
          docker ps -a
          docker wait automation-exercise-tests

          if [ "${{ env.SHOW_LOGS }}" = "true" ]; then
            echo "### Test logs ###"
            docker logs automation-exercise-tests
          fi

        continue-on-error: true

      - name: Clear compose data
        if: always()
        run: |
          docker compose rm -sf
          docker rmi ${{ env.PREFIX }}/automation-exercise-tests:latest

      - name: Update env variables for SCREENSHOT test run
        if: always()
        run: |
          echo "PYTEST_MARK_EXPR=${{ vars.PYTEST_MARK_EXPR_SCREENSHOT }}" >> $GITHUB_ENV
          echo "PYTEST_ARGS=${{ vars.PYTEST_ARGS_SCREENSHOT }}" >> $GITHUB_ENV
          echo "PAGE_LOAD_STRATEGY=normal" >> $GITHUB_ENV

      - name: Run SCREENSHOT tests
        id: screenshot_test_run
        if: always()
        run: |
          set -euo pipefail

          docker compose -f docker-compose.ci.yaml up -d
          docker ps -a
          docker wait automation-exercise-tests

          if [ "${{ env.SHOW_LOGS }}" = "true" ]; then
            echo "### Test logs ###"
            docker logs automation-exercise-tests
          fi

        continue-on-error: true

      - name: Get Allure history
        uses: actions/checkout@v2
        if: always()
        continue-on-error: true
        with:
          ref: gh-pages
          path: gh-pages

      - name: Allure Report action from marketplace
        uses: simple-elf/allure-report-action@master
        if: always()
        #id: allure-report
        with:
          report_name: Nightly run ${{ env.CURRENT_DATE_TIME }}
          allure_results: allure-results
          #gh_pages: gh-pages
          #allure_report: allure-report
          allure_history: allure-history

      - name: Deploy report to Github Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v2
        env:
          PERSONAL_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PUBLISH_BRANCH: gh-pages
          PUBLISH_DIR: allure-history

      - name: Parse Test Statistics
        id: stats
        run: |
          # Install jq for JSON parsing
          sudo apt-get install -y jq
          # Parse categories from Allure results (assuming categories.json exists in allure-results)
          if [ -f allure-results/categories.json ]; then
            PASSED=$(jq '.[] | select(.name == "passed") | .matched' allure-results/categories.json || echo 0)
            FAILED=$(jq '.[] | select(.name == "failed") | .matched' allure-results/categories.json || echo 0)
            BROKEN=$(jq '.[] | select(.name == "broken") | .matched' allure-results/categories.json || echo 0)
            SKIPPED=$(jq '.[] | select(.name == "skipped") | .matched' allure-results/categories.json || echo 0)
            UNKNOWN=$(jq '.[] | select(.name == "unknown") | .matched' allure-results/categories.json || echo 0)
          else
            # Fallback: count result files
            PASSED=$(find allure-results -name '*.json' | xargs jq '.status' | grep -c "passed")
            FAILED=$(find allure-results -name '*.json' | xargs jq '.status' | grep -c "failed")
            BROKEN=$(find allure-results -name '*.json' | xargs jq '.status' | grep -c "broken")
            SKIPPED=$(find allure-results -name '*.json' | xargs jq '.status' | grep -c "skipped")
            UNKNOWN=$(find allure-results -name '*.json' | xargs jq '.status' | grep -c "unknown")
          fi
          TOTAL=$((PASSED + FAILED + BROKEN + SKIPPED + UNKNOWN))
          PASS_RATE=$(awk "BEGIN {printf \"%.3f\", ($PASSED / $TOTAL) * 100}")
          echo "PASSED=$PASSED" >> $GITHUB_OUTPUT
          echo "FAILED=$FAILED" >> $GITHUB_OUTPUT
          echo "BROKEN=$BROKEN" >> $GITHUB_OUTPUT
          echo "SKIPPED=$SKIPPED" >> $GITHUB_OUTPUT
          echo "UNKNOWN=$UNKNOWN" >> $GITHUB_OUTPUT
          echo "TOTAL=$TOTAL" >> $GITHUB_OUTPUT
          echo "PASS_RATE=$PASS_RATE" >> $GITHUB_OUTPUT
          echo "IS_PASSED=$IS_PASSED" >> $GITHUB_OUTPUT

      - name: Quality gate
        id: quality_gate
        run: |

          expected_pass_rate = ${{ env.TESTS_PASS_RATE }}
          actual_pass_rate = ${{steps.stats.outputs.PASS_RATE}}

          if [ $(echo "$actual_pass_rate < $expected_pass_rate" | bc -l) -eq 1 ]; then
            echo "Quality gate failed: Actual pass rate $actual_pass_rate% < Expected $expected_pass_rate%"
            exit 1
          fi

          echo "Quality gate passed: Actual pass rate $actual_pass_rate% >= Expected $expected_pass_rate%"

      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          script: |

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const marker = '<!-- TEST RUN COMMENT -->';
            const existing = comments.find(comment => comment.body.includes(marker));
            const reportUrl = `https://${{ github.repository_owner }}.github.io/${{ github.repository }}/reports/${{ github.run_id }}/index.html`;
            const historyUrl = `https://${{ github.repository_owner }}.github.io/${{ github.repository }}/`;
            const body = `${marker}
            âœ… TEST RUN PASSED âœ…
            ğŸ“‹ Test Statistics:
            | Status | Count |
            |--------|-------|
            | âœ… Passed | ${{ steps.stats.outputs.PASSED }} |
            | ğŸ”´ Failed | ${{ steps.stats.outputs.FAILED }} |
            | ğŸŸ  Broken | ${{ steps.stats.outputs.BROKEN }} |
            | â© Skipped | ${{ steps.stats.outputs.SKIPPED }} |
            | â“ Unknown | ${{ steps.stats.outputs.UNKNOWN }} |
            | ğŸ“Š Total | ${{ steps.stats.outputs.TOTAL }} |
            ğŸ“ˆ Pass Rate ${{ steps.stats.outputs.PASS_RATE }}%
            There is the [report](${reportUrl})
            ğŸ•“ All [reports history](${historyUrl})
            `;

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }